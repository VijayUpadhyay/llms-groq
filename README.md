# llms-groq

This will have test code which will create a Groq client using the apikey and try to communicate with the model and get the answer for the questions

- Get API key groq.com and use it to create Groq Client. Use the client to initiate the communication with the Groq LLM

- For Ollama: run command: ollama serve
